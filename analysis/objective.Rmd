---
title: "Decreases in the FLASH objective function"
author: "Jason Willwerscheid"
date: "7/14/2018"
output:
  workflowr::wflow_html
---

## Introduction

Here I begin to look into why the FLASH objective function can decrease after an iteration.

## Example

I'm using the "strong" tests from the MASH paper GTEx dataset. The first problem appears when fitting the fourth factor. Notice that in the final iteration, the objective decreases by a very small amount and a warning is displayed.

```{r example}
# devtools::install_github("stephenslab/flashr", ref="trackObj")
devtools::load_all("/Users/willwerscheid/GitHub/flashr")
# devtools::install_github("stephenslab/ebnm")
devtools::load_all("/Users/willwerscheid/GitHub/ebnm")

gtex <- readRDS(gzcon(url("https://github.com/stephenslab/gtexresults/blob/master/data/MatrixEQTLSumStats.Portable.Z.rds?raw=TRUE")))
strong <- gtex$strong.z
res <- flash_add_greedy(strong, Kmax=3, verbose=FALSE)
res <- flash_add_greedy(strong, f_init=res$f, Kmax=1, verbose=TRUE)
```

## Illustration of problem

A more granular tracking of the objective function reveals a larger problem. Recall that there are three steps in each iteration: updating the precision matrix, updating the factors (via the prior $g_f$), and updating the loadings (via $g_l$). Plotting the objective after each step rather than each iteration reveals a sawtooth pattern. I discard the first 8 iterations in order to zoom in on the problem area. (See branch `trackObj`, file `r1_opt.R` for the code used to obtain these results.)

```{r plot}
obj_data <- as.vector(rbind(res$obj[[1]]$after_tau,
                            res$obj[[1]]$after_f,
                            res$obj[[1]]$after_l))
max_obj <- max(obj_data)
obj_data <- obj_data - max_obj
iter <- 1:length(obj_data) / 3

plt_xlab = "Iteration"
plt_ylab = "Diff. from maximum obj."
# plot(iter, obj_data, type='l', xlab=plt_xlab, ylab=plt_ylab)

obj_data <- obj_data[-(1:24)]
iter <- iter[-(1:24)]
plt_colors <- c("indianred1", "indianred3", "indianred4")
plt_pch <- c(16, 17, 15)

plot(iter, obj_data, col=plt_colors, pch=plt_pch,
     xlab=plt_xlab, ylab=plt_ylab)
legend("bottomright", c("after tau", "after f", "after l"),
       col=plt_colors, pch=plt_pch)
```

## Analysis

I backtrack to just before the "bad" update. 

```{r slow1}
res2 <- flash_add_greedy(strong, Kmax=4, stopAtObj = -1297148.032)
flash_get_objective(strong, res2$f) - flash_get_objective(strong, res$f)
```

So at this point, the objective is indeed better than for the flash fit obtained above.

Now, I update the precision.

```{r slow2}
fl <- res2$f
data <- flash_set_data(strong)
k <- 4
init_fl = fl

R2 = flashr:::flash_get_R2(data, fl)
fl$tau = flashr:::compute_precision(R2, data$missing, 
                                    "by_column", data$S)
flash_get_objective(strong, fl) - flash_get_objective(strong, init_fl)
```

So, as expected, the overall objective increases. Next I update the loadings (FLASH updates factors first, but the order of updates is not supposed to affect the monotonicity of the objective function).

```{r slow4}
last_fl = fl

s2 = 1/(fl$EF2[, k] %*% t(fl$tau))
s = sqrt(s2)
Rk = flashr:::flash_get_Rk(data, fl, k)
x = fl$EF[, k] %*% t(Rk * fl$tau) * s2
ebnm_l = flashr:::ebnm_pn(x, s, list())
KL_l = (ebnm_l$penloglik 
        - flashr:::NM_posterior_e_loglik(x, s, ebnm_l$postmean,
                                         ebnm_l$postmean2))

fl$EL[, k] = ebnm_l$postmean
fl$EL2[, k] = ebnm_l$postmean2
fl$gl[[k]] = ebnm_l$fitted_g
fl$KL_l[[k]] = KL_l
flash_get_objective(data, fl) - flash_get_objective(data, last_fl)
```

So the objective has in fact gotten worse. And tightening the control parameters or changing the initialization for the `ebnm` function does not help matters. For example, tightening the tolerance parameter by adding `factr = 100` does not change anything:

```{r slow5}
s2 = 1/(fl$EF2[, k] %*% t(fl$tau))
s = sqrt(s2)
Rk = flashr:::flash_get_Rk(data, fl, k)
x = fl$EF[, k] %*% t(Rk * fl$tau) * s2
ebnm_l = flashr:::ebnm_pn(x, s, list(control=list(factr=100)))
KL_l = (ebnm_l$penloglik 
        - flashr:::NM_posterior_e_loglik(x, s, ebnm_l$postmean,
                                         ebnm_l$postmean2))

fl$EL[, k] = ebnm_l$postmean
fl$EL2[, k] = ebnm_l$postmean2
fl$gl[[k]] = ebnm_l$fitted_g
fl$KL_l[[k]] = KL_l
flash_get_objective(data, fl) - flash_get_objective(data, last_fl)
```

## Conclusions

The decrease appears too large to be explained by numerical error. Indeed, it would be very surprising to me if `EL` and `EL2` could only be trusted to five digits or so (as would have to be the case to produce errors of the above magnitude). 

More seriously, the sawtooth pattern depicted above points to a more regular feature of the optimization. The theory appears to be sound, so what is going on here?
